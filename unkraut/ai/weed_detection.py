# unkraut/ai/weed_detection_selective.py
"""
SELEKTIVER HSV-Fix f√ºr Unkraut-Erkennung
Fokus auf Kontrast-basierte Erkennung statt globaler HSV-Filter
"""
import cv2
import numpy as np
import time
import random
from datetime import datetime
import os

class WeedDetector:
    def __init__(self):
        self.model_loaded = False
        self.model = None
        self.detection_count = 0
        self.debug_mode = False
        
        # Optimierte Einstellungen
        self.confidence_threshold = 0.2  # Sehr niedrig
        self.min_area = 100              # Sehr niedrig
        self.max_area = 50000           # Hoch
        self.sensitivity = 0.9          # Hoch
        
        # SELEKTIVE Gr√ºn-Profile - fokus auf Kontrast
        self.green_profiles = {
            'contrast_based': {
                'lower': np.array([50, 100, 80]),   # Nur mittlere bis hohe S√§ttigung
                'upper': np.array([70, 255, 200]),  # Begrenzte Helligkeit
                'name': 'Kontrast-basiert'
            },
            'bright_only': {
                'lower': np.array([55, 120, 100]),  # Nur helle Bereiche
                'upper': np.array([65, 255, 180]),
                'name': 'Nur helle Bereiche'
            },
            'analyzed_selective': {
                'lower': np.array([58, 150, 100]),  # Basierend auf Analyse, aber selektiver
                'upper': np.array([62, 210, 170]),
                'name': 'Analysiert + Selektiv'
            }
        }
        
        self.current_profile = 'contrast_based'
        self.init_ai_model()
    
    def init_ai_model(self):
        """KI-Modell initialisieren"""
        self.model_loaded = False
        if self.debug_mode:
            print("üîß Selektive OpenCV-Erkennung aktiviert")
    
    def log(self, message):
        """Debug-Logging"""
        if self.debug_mode:
            timestamp = datetime.now().strftime("%H:%M:%S")
            print(f"[{timestamp}] WeedDetector: {message}")
    
    def detect_from_bytes(self, image_bytes):
        """Unkraut in Bild-Bytes erkennen"""
        try:
            nparr = np.frombuffer(image_bytes, np.uint8)
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if image is None:
                return {'error': 'Invalid image data'}
            
            return self.detect_in_image(image)
            
        except Exception as e:
            return {'error': f'Detection failed: {str(e)}'}
    
    def detect_in_image(self, image):
        """Haupterkennungsfunktion mit selektiver Erkennung"""
        start_time = time.time()
        
        try:
            # Versuche verschiedene Ans√§tze
            detections = []
            
            # 1. Kontrast-basierte Erkennung
            detections = self._contrast_based_detection(image)
            
            # 2. Wenn keine Erkennungen, versuche Helligkeits-basiert
            if not detections:
                self.log("Keine Kontrast-Erkennungen - versuche Helligkeits-basiert")
                detections = self._brightness_based_detection(image)
            
            # 3. Wenn immer noch keine Erkennungen, versuche adaptiv
            if not detections:
                self.log("Keine Helligkeits-Erkennungen - versuche adaptiv")
                detections = self._adaptive_detection(image)
            
            # 4. Fallback auf intelligente Mock-Daten
            if not detections:
                self.log("Keine Erkennungen - verwende intelligente Mock-Daten")
                detections = self._smart_mock_detection(image)
                method = 'opencv_mock'
            else:
                method = 'opencv_selective'
            
            processing_time = time.time() - start_time
            self.detection_count += 1
            
            result = {
                'detections': detections,
                'count': len(detections),
                'confidence': self._calculate_average_confidence(detections),
                'processing_time': round(processing_time, 3),
                'timestamp': int(time.time()),
                'detection_id': self.detection_count,
                'image_size': {'width': image.shape[1], 'height': image.shape[0]},
                'method': method,
                'profile': self.green_profiles[self.current_profile]['name']
            }
            
            self.log(f"‚úÖ Erkennung #{self.detection_count}: {len(detections)} Objekte ({method})")
            return result
            
        except Exception as e:
            self.log(f"‚ùå Fehler bei Erkennung: {e}")
            return {
                'error': str(e),
                'detections': [],
                'count': 0,
                'processing_time': time.time() - start_time,
                'method': 'error_fallback'
            }
    
    def _contrast_based_detection(self, image):
        """Kontrast-basierte Erkennung - findet hellere Bereiche"""
        try:
            detections = []
            
            # 1. Konvertiere zu verschiedenen Farbr√§umen
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # 2. Finde helle Bereiche durch Kontrast
            mean_brightness = gray.mean()
            bright_threshold = mean_brightness + 20  # 20 Punkte heller als Durchschnitt
            
            # Erstelle Helligkeits-Maske
            brightness_mask = gray > bright_threshold
            
            # 3. Kombiniere mit HSV-Filter
            profile = self.green_profiles[self.current_profile]
            hsv_mask = cv2.inRange(hsv, profile['lower'], profile['upper'])
            
            # 4. Kombiniere beide Masken (UND-Verkn√ºpfung)
            combined_mask = cv2.bitwise_and(brightness_mask.astype(np.uint8) * 255, hsv_mask)
            
            green_pixels = cv2.countNonZero(combined_mask)
            total_pixels = image.shape[0] * image.shape[1]
            percentage = (green_pixels / total_pixels) * 100
            
            self.log(f"Kontrast-Filter: {green_pixels} Pixel ({percentage:.1f}%)")
            
            # 5. Sanfte Morphologie
            kernel = np.ones((2, 2), np.uint8)
            combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel)
            combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel)
            
            # 6. Konturen finden
            contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            self.log(f"Kontrast-Konturen gefunden: {len(contours)}")
            
            # 7. Analysiere Konturen
            for i, contour in enumerate(contours):
                area = cv2.contourArea(contour)
                
                if area < self.min_area or area > self.max_area:
                    continue
                
                # Bounding Box
                x, y, w, h = cv2.boundingRect(contour)
                center_x = x + w // 2
                center_y = y + h // 2
                
                # Einfache aber effektive Confidence
                # Basierend auf: Gr√∂√üe, Position, Kontrast
                size_score = min(1.0, area / 1000) * 0.4
                
                # Position-Score (nicht zu nah am Rand)
                margin = 30
                if margin < center_x < image.shape[1] - margin and margin < center_y < image.shape[0] - margin:
                    position_score = 0.3
                else:
                    position_score = 0.1
                
                # Kontrast-Score (Helligkeit des Bereichs)
                roi_gray = gray[y:y+h, x:x+w]
                roi_brightness = roi_gray.mean()
                contrast_score = min(0.3, (roi_brightness - mean_brightness) / 50)
                
                confidence = size_score + position_score + contrast_score
                confidence = min(0.95, max(0.1, confidence))
                
                if confidence >= self.confidence_threshold:
                    # Klassifizierung
                    aspect_ratio = w / h if h > 0 else 1
                    if area > 2000:
                        weed_type = 'large_weed'
                    elif aspect_ratio > 1.8:
                        weed_type = 'tall_weed'
                    elif aspect_ratio < 0.6:
                        weed_type = 'wide_weed'
                    else:
                        weed_type = 'common_weed'
                    
                    detection = {
                        'class': 'weed',
                        'subclass': weed_type,
                        'confidence': round(confidence, 3),
                        'bbox': {'x': x, 'y': y, 'width': w, 'height': h},
                        'center': {'x': center_x, 'y': center_y},
                        'area': int(area),
                        'brightness': round(roi_brightness, 1),
                        'contrast': round(roi_brightness - mean_brightness, 1),
                        'x': center_x,
                        'y': center_y,
                        'id': i + 1,
                        'method': 'contrast'
                    }
                    
                    detections.append(detection)
                    
                    self.log(f"  ‚Üí Kontrast-Unkraut {len(detections)}: {weed_type}, "
                           f"Confidence {confidence:.3f}, Kontrast +{roi_brightness - mean_brightness:.1f}")
            
            return detections
            
        except Exception as e:
            self.log(f"‚ùå Kontrast-Erkennung fehlgeschlagen: {e}")
            return []
    
    def _brightness_based_detection(self, image):
        """Helligkeits-basierte Erkennung"""
        try:
            detections = []
            
            # Konvertiere zu HSV
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
            
            # Verwende V-Kanal (Brightness) direkt
            v_channel = hsv[:, :, 2]
            
            # Finde obere 10% der hellsten Bereiche
            brightness_threshold = np.percentile(v_channel, 90)
            
            # Erstelle Maske f√ºr helle Bereiche
            bright_mask = v_channel > brightness_threshold
            
            # Kombiniere mit grundlegender Gr√ºn-Erkennung
            h_channel = hsv[:, :, 0]
            green_mask = (h_channel >= 50) & (h_channel <= 70)  # Gr√ºn-Bereich
            
            # Kombiniere
            combined_mask = bright_mask & green_mask
            
            # Konvertiere zu uint8
            combined_mask = combined_mask.astype(np.uint8) * 255
            
            # Konturen
            contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            self.log(f"Helligkeits-Konturen gefunden: {len(contours)}")
            
            for i, contour in enumerate(contours):
                area = cv2.contourArea(contour)
                
                if area < 50:  # Sehr niedrige Schwelle
                    continue
                
                x, y, w, h = cv2.boundingRect(contour)
                center_x = x + w // 2
                center_y = y + h // 2
                
                # Einfache Confidence
                confidence = min(0.8, area / 500) * self.sensitivity
                
                if confidence >= 0.1:  # Sehr niedrige Schwelle
                    detection = {
                        'class': 'weed',
                        'subclass': 'bright_weed',
                        'confidence': round(confidence, 3),
                        'bbox': {'x': x, 'y': y, 'width': w, 'height': h},
                        'center': {'x': center_x, 'y': center_y},
                        'area': int(area),
                        'x': center_x,
                        'y': center_y,
                        'id': i + 1,
                        'method': 'brightness'
                    }
                    
                    detections.append(detection)
            
            return detections[:5]  # Max 5
            
        except Exception as e:
            self.log(f"‚ùå Helligkeits-Erkennung fehlgeschlagen: {e}")
            return []
    
    def _adaptive_detection(self, image):
        """Adaptive Erkennung mit automatischer Schwellwert-Anpassung"""
        try:
            detections = []
            
            # Adaptive Threshold-Methode
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # Adaptive Threshold
            adaptive_thresh = cv2.adaptiveThreshold(
                gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2
            )
            
            # Invertiere um helle Bereiche zu finden
            adaptive_thresh = cv2.bitwise_not(adaptive_thresh)
            
            # Konturen
            contours, _ = cv2.findContours(adaptive_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            self.log(f"Adaptive Konturen gefunden: {len(contours)}")
            
            for i, contour in enumerate(contours):
                area = cv2.contourArea(contour)
                
                if 30 < area < 5000:  # Moderate Gr√∂√üe
                    x, y, w, h = cv2.boundingRect(contour)
                    center_x = x + w // 2
                    center_y = y + h // 2
                    
                    confidence = min(0.7, area / 1000)
                    
                    if confidence >= 0.05:
                        detection = {
                            'class': 'weed',
                            'subclass': 'adaptive_weed',
                            'confidence': round(confidence, 3),
                            'bbox': {'x': x, 'y': y, 'width': w, 'height': h},
                            'center': {'x': center_x, 'y': center_y},
                            'area': int(area),
                            'x': center_x,
                            'y': center_y,
                            'id': i + 1,
                            'method': 'adaptive'
                        }
                        
                        detections.append(detection)
            
            return detections[:4]  # Max 4
            
        except Exception as e:
            self.log(f"‚ùå Adaptive Erkennung fehlgeschlagen: {e}")
            return []
    
    def _smart_mock_detection(self, image):
        """Intelligente Mock-Erkennung als Fallback"""
        detections = []
        h, w = image.shape[:2]
        
        # Basierend auf Dateinamen intelligente Anzahl
        num_detections = random.randint(1, 3)
        
        for i in range(num_detections):
            x = random.randint(w//8, w - w//8 - 50)
            y = random.randint(h//8, h - h//8 - 50)
            width = random.randint(20, 60)
            height = random.randint(20, 60)
            confidence = random.uniform(0.3, 0.8)
            
            detection = {
                'class': 'weed',
                'subclass': 'mock_weed',
                'confidence': round(confidence, 3),
                'bbox': {'x': x, 'y': y, 'width': width, 'height': height},
                'center': {'x': x + width//2, 'y': y + height//2},
                'area': width * height,
                'x': x + width//2,
                'y': y + height//2,
                'id': i + 1,
                'mock': True
            }
            
            detections.append(detection)
        
        return detections
    
    def _calculate_average_confidence(self, detections):
        """Durchschnittliche Confidence"""
        if not detections:
            return 0.0
        
        total_confidence = sum(d['confidence'] for d in detections)
        return round(total_confidence / len(detections), 3)
    
    def draw_detections(self, image, detections):
        """Erkennungen zeichnen mit Methoden-Kennzeichnung"""
        result_image = image.copy()
        
        for detection in detections:
            bbox = detection['bbox']
            confidence = detection['confidence']
            weed_type = detection.get('subclass', 'unknown')
            method = detection.get('method', 'unknown')
            is_mock = detection.get('mock', False)
            
            # Farbe basierend auf Methode
            if is_mock:
                color = (0, 0, 255)         # Rot f√ºr Mock
            elif method == 'contrast':
                color = (0, 255, 0)         # Gr√ºn f√ºr Kontrast
            elif method == 'brightness':
                color = (255, 255, 0)       # Cyan f√ºr Helligkeit
            elif method == 'adaptive':
                color = (255, 0, 255)       # Magenta f√ºr Adaptiv
            else:
                color = (0, 255, 255)       # Gelb f√ºr andere
            
            # Bounding Box
            cv2.rectangle(result_image, 
                         (bbox['x'], bbox['y']), 
                         (bbox['x'] + bbox['width'], bbox['y'] + bbox['height']), 
                         color, 2)
            
            # Zentrum
            center = (detection['center']['x'], detection['center']['y'])
            cv2.circle(result_image, center, 3, color, -1)
            
            # Label mit Methode
            label_parts = [weed_type.replace('_weed', ''), f"{confidence:.2f}"]
            if not is_mock:
                label_parts.append(method.upper())
            else:
                label_parts.append("MOCK")
            
            label = " ".join(label_parts)
            cv2.putText(result_image, label, 
                       (bbox['x'], bbox['y'] - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
        
        return result_image
    
    def get_detection_stats(self):
        """Erkennungsstatistiken"""
        return {
            'total_detections': self.detection_count,
            'model_loaded': self.model_loaded,
            'confidence_threshold': self.confidence_threshold,
            'min_area': self.min_area,
            'current_profile': self.current_profile,
            'method': 'opencv_selective'
        }
    
    def set_confidence_threshold(self, threshold):
        """Confidence-Schwellwert setzen"""
        self.confidence_threshold = max(0.05, min(0.9, threshold))
        self.log(f"üéØ Confidence-Schwellwert: {self.confidence_threshold}")

# Globale Instanz
weed_detector = WeedDetector()