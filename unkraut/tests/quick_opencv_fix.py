# unkraut/ai/weed_detection_fixed.py
"""
SCHNELL-FIX f√ºr OpenCV-Erkennung
Tolerantere HSV-Werte und niedrigere Schwellwerte
"""
import cv2
import numpy as np
import time
import random
from datetime import datetime
import os

class WeedDetector:
    def __init__(self):
        self.model_loaded = False
        self.model = None
        self.detection_count = 0
        self.debug_mode = False
        
        # GEFIXTE Einstellungen - toleranter
        self.confidence_threshold = 0.3  # Gesenkt von 0.5
        self.min_area = 200              # Gesenkt von 300
        self.max_area = 20000           # Erh√∂ht von 15000
        self.sensitivity = 0.8          # Erh√∂ht von 0.7
        
        # VERBESSERTE Gr√ºn-Profile - toleranter
        self.green_profiles = {
            'bright': {
                'lower': np.array([30, 40, 40]),    # Erweitert
                'upper': np.array([90, 255, 255]),
                'name': 'Helles Gr√ºn'
            },
            'dark': {
                'lower': np.array([25, 30, 30]),    # Toleranter
                'upper': np.array([95, 255, 200]),
                'name': 'Dunkles Gr√ºn'
            },
            'mixed': {
                'lower': np.array([20, 25, 25]),    # Viel toleranter
                'upper': np.array([100, 255, 255]),
                'name': 'Gemischtes Gr√ºn (tolerant)'
            },
            'very_tolerant': {
                'lower': np.array([15, 20, 20]),    # Sehr tolerant
                'upper': np.array([105, 255, 255]),
                'name': 'Sehr tolerant'
            }
        }
        
        self.current_profile = 'very_tolerant'  # Tolerantestes Profil
        self.init_ai_model()
    
    def init_ai_model(self):
        """KI-Modell initialisieren"""
        try:
            import tensorflow as tf
            if self.debug_mode:
                print("‚ö†Ô∏è Kein trainiertes Modell gefunden")
                print("üí° Verwende verbesserte OpenCV-Erkennung")
        except ImportError:
            if self.debug_mode:
                print("‚ö†Ô∏è TensorFlow nicht installiert")
        
        self.model_loaded = False
        if self.debug_mode:
            print("üîß Verbesserte OpenCV-Erkennung aktiviert")
    
    def log(self, message):
        """Debug-Logging"""
        if self.debug_mode:
            timestamp = datetime.now().strftime("%H:%M:%S")
            print(f"[{timestamp}] WeedDetector: {message}")
    
    def detect_from_bytes(self, image_bytes):
        """Unkraut in Bild-Bytes erkennen"""
        try:
            nparr = np.frombuffer(image_bytes, np.uint8)
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if image is None:
                return {'error': 'Invalid image data'}
            
            return self.detect_in_image(image)
            
        except Exception as e:
            return {'error': f'Detection failed: {str(e)}'}
    
    def detect_in_image(self, image):
        """Haupterkennungsfunktion - VERBESSERT"""
        start_time = time.time()
        
        try:
            # Versuche zuerst erweiterte OpenCV-Erkennung
            detections = self._enhanced_opencv_detection(image)
            
            # Wenn keine Erkennungen, versuche tolerantere Einstellungen
            if not detections:
                self.log("Keine Erkennungen - versuche tolerantere Einstellungen")
                detections = self._fallback_detection(image)
            
            # Wenn immer noch keine Erkennungen, Mock verwenden
            if not detections:
                self.log("Keine Erkennungen - verwende Mock")
                detections = self._smart_mock_detection(image)
                method = 'opencv_mock'
            else:
                method = 'opencv_enhanced'
            
            processing_time = time.time() - start_time
            self.detection_count += 1
            
            result = {
                'detections': detections,
                'count': len(detections),
                'confidence': self._calculate_average_confidence(detections),
                'processing_time': round(processing_time, 3),
                'timestamp': int(time.time()),
                'detection_id': self.detection_count,
                'image_size': {'width': image.shape[1], 'height': image.shape[0]},
                'method': method,
                'profile': self.green_profiles[self.current_profile]['name']
            }
            
            self.log(f"‚úÖ Erkennung #{self.detection_count}: {len(detections)} Objekte ({method})")
            return result
            
        except Exception as e:
            self.log(f"‚ùå Fehler bei Erkennung: {e}")
            return {
                'error': str(e),
                'detections': [],
                'count': 0,
                'processing_time': time.time() - start_time,
                'method': 'error_fallback'
            }
    
    def _enhanced_opencv_detection(self, image):
        """Verbesserte OpenCV-Erkennung"""
        try:
            detections = []
            
            # 1. Bild vorverarbeiten
            blurred = cv2.GaussianBlur(image, (3, 3), 0)  # Weniger Blur
            hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)
            
            # 2. Gr√ºn-Maske mit toleranteren Werten
            profile = self.green_profiles[self.current_profile]
            mask = cv2.inRange(hsv, profile['lower'], profile['upper'])
            
            self.log(f"Gr√ºn-Pixel gefunden: {cv2.countNonZero(mask)}")
            
            # 3. Weniger aggressive Morphologie
            kernel = np.ones((3, 3), np.uint8)  # Kleinerer Kernel
            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
            
            # 4. Konturen finden
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            self.log(f"Konturen gefunden: {len(contours)}")
            
            # 5. Konturen analysieren - toleranter
            for i, contour in enumerate(contours):
                area = cv2.contourArea(contour)
                
                # Weniger restriktive Gr√∂√üenfilter
                if area < self.min_area or area > self.max_area:
                    continue
                
                # Bounding Box
                x, y, w, h = cv2.boundingRect(contour)
                center_x = x + w // 2
                center_y = y + h // 2
                
                # Eigenschaften berechnen
                perimeter = cv2.arcLength(contour, True)
                circularity = (4 * np.pi * area) / (perimeter ** 2) if perimeter > 0 else 0
                aspect_ratio = w / h if h > 0 else 1
                
                # Tolerantere Confidence-Berechnung
                size_score = min(1.0, area / 1000) * 0.5  # Niedrigere Erwartung
                form_score = 0.3  # Weniger wichtig
                base_confidence = (size_score + form_score) * self.sensitivity
                
                # Bonus f√ºr gr√∂√üere Objekte
                if area > 1000:
                    base_confidence += 0.2
                
                confidence = min(0.95, base_confidence)
                
                # Niedrigere Schwelle
                if confidence >= self.confidence_threshold:
                    # Unkraut-Typ bestimmen
                    if area > 2000:
                        weed_type = 'large_weed'
                    elif aspect_ratio > 1.5:
                        weed_type = 'tall_weed'
                    else:
                        weed_type = 'common_weed'
                    
                    detection = {
                        'class': 'weed',
                        'subclass': weed_type,
                        'confidence': round(confidence, 3),
                        'bbox': {'x': x, 'y': y, 'width': w, 'height': h},
                        'center': {'x': center_x, 'y': center_y},
                        'area': int(area),
                        'circularity': round(circularity, 3),
                        'aspect_ratio': round(aspect_ratio, 3),
                        'x': center_x,
                        'y': center_y,
                        'id': i + 1
                    }
                    
                    detections.append(detection)
            
            # Nach Confidence sortieren
            detections.sort(key=lambda x: x['confidence'], reverse=True)
            
            # Maximal 8 Erkennungen
            detections = detections[:8]
            
            self.log(f"üîç OpenCV-Erkennung: {len(detections)} Unkr√§uter gefunden")
            return detections
            
        except Exception as e:
            self.log(f"‚ùå OpenCV-Erkennung fehlgeschlagen: {e}")
            return []
    
    def _fallback_detection(self, image):
        """Fallback mit noch toleranteren Einstellungen"""
        try:
            # Noch tolerantere HSV-Werte
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
            
            # Sehr weite Gr√ºn-Bereiche
            lower_green = np.array([10, 15, 15])
            upper_green = np.array([110, 255, 255])
            
            mask = cv2.inRange(hsv, lower_green, upper_green)
            
            # Minimale Morphologie
            kernel = np.ones((2, 2), np.uint8)
            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
            
            # Konturen
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            detections = []
            for i, contour in enumerate(contours):
                area = cv2.contourArea(contour)
                
                # Sehr niedrige Mindestgr√∂√üe
                if area < 100:
                    continue
                
                x, y, w, h = cv2.boundingRect(contour)
                center_x = x + w // 2
                center_y = y + h // 2
                
                # Einfache Confidence
                confidence = min(0.8, area / 500)
                
                if confidence >= 0.2:  # Sehr niedrige Schwelle
                    detection = {
                        'class': 'weed',
                        'subclass': 'detected_weed',
                        'confidence': round(confidence, 3),
                        'bbox': {'x': x, 'y': y, 'width': w, 'height': h},
                        'center': {'x': center_x, 'y': center_y},
                        'area': int(area),
                        'x': center_x,
                        'y': center_y,
                        'id': i + 1,
                        'fallback': True
                    }
                    
                    detections.append(detection)
            
            return detections[:5]
            
        except Exception as e:
            self.log(f"‚ùå Fallback-Erkennung fehlgeschlagen: {e}")
            return []
    
    def _smart_mock_detection(self, image):
        """Intelligente Mock-Erkennung basierend auf Bildinhalt"""
        detections = []
        
        # Analysiere Bild um realistische Mock-Daten zu generieren
        h, w = image.shape[:2]
        
        # Berechne realistische Anzahl basierend auf Bildgr√∂√üe
        expected_weeds = max(1, (w * h) // 100000)  # ~1 Unkraut pro 100k Pixel
        num_detections = random.randint(1, min(4, expected_weeds))
        
        for i in range(num_detections):
            # Realistische Position
            x = random.randint(w//8, w - w//8 - 60)
            y = random.randint(h//8, h - h//8 - 60)
            
            # Realistische Gr√∂√üe
            base_size = random.randint(20, 60)
            width = base_size + random.randint(-5, 15)
            height = base_size + random.randint(-5, 15)
            
            # Realistische Confidence
            confidence = random.uniform(0.4, 0.8)
            
            # Typ basierend auf Gr√∂√üe
            area = width * height
            if area > 2000:
                weed_type = 'large_weed'
            elif height > width * 1.5:
                weed_type = 'tall_weed'
            else:
                weed_type = 'common_weed'
            
            detection = {
                'class': 'weed',
                'subclass': weed_type,
                'confidence': round(confidence, 3),
                'bbox': {'x': x, 'y': y, 'width': width, 'height': height},
                'center': {'x': x + width//2, 'y': y + height//2},
                'area': area,
                'x': x + width//2,
                'y': y + height//2,
                'id': i + 1,
                'mock': True
            }
            
            detections.append(detection)
        
        return detections
    
    def _calculate_average_confidence(self, detections):
        """Durchschnittliche Confidence"""
        if not detections:
            return 0.0
        
        total_confidence = sum(d['confidence'] for d in detections)
        return round(total_confidence / len(detections), 3)
    
    def draw_detections(self, image, detections):
        """Erkennungen auf Bild zeichnen"""
        result_image = image.copy()
        
        for detection in detections:
            bbox = detection['bbox']
            confidence = detection['confidence']
            weed_type = detection.get('subclass', 'unknown')
            is_mock = detection.get('mock', False)
            is_fallback = detection.get('fallback', False)
            
            # Farbe basierend auf Typ
            if is_mock:
                color = (0, 0, 255)     # Rot f√ºr Mock
            elif is_fallback:
                color = (255, 0, 0)     # Blau f√ºr Fallback
            elif confidence > 0.7:
                color = (0, 255, 0)     # Gr√ºn f√ºr hohe Confidence
            else:
                color = (0, 255, 255)   # Gelb f√ºr niedrige Confidence
            
            # Bounding Box
            cv2.rectangle(result_image, 
                         (bbox['x'], bbox['y']), 
                         (bbox['x'] + bbox['width'], bbox['y'] + bbox['height']), 
                         color, 2)
            
            # Zentrum
            center = (detection['center']['x'], detection['center']['y'])
            cv2.circle(result_image, center, 3, color, -1)
            
            # Label
            label_parts = [weed_type, f"{confidence:.2f}"]
            if is_mock:
                label_parts.append("MOCK")
            elif is_fallback:
                label_parts.append("FALLBACK")
            
            label = " ".join(label_parts)
            cv2.putText(result_image, label, 
                       (bbox['x'], bbox['y'] - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
        
        return result_image
    
    def get_detection_stats(self):
        """Erkennungsstatistiken"""
        return {
            'total_detections': self.detection_count,
            'model_loaded': self.model_loaded,
            'confidence_threshold': self.confidence_threshold,
            'min_area': self.min_area,
            'current_profile': self.current_profile,
            'method': 'tensorflow' if self.model_loaded else 'opencv_enhanced'
        }
    
    def set_confidence_threshold(self, threshold):
        """Confidence-Schwellwert setzen"""
        self.confidence_threshold = max(0.1, min(0.9, threshold))
        self.log(f"üéØ Confidence-Schwellwert: {self.confidence_threshold}")

# Globale Instanz
weed_detector = WeedDetector()
